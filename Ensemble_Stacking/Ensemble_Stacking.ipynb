{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.model_selection import cross_validate\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data\n",
    "Data is shuffled and the nan rows are dropped. Since I use CV, 680 samples are selected from total of 683 samples.\n",
    "\n",
    "In these models, I did not optimized the parameters of classifier. I simply used all the defaults."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(680, 9) (680,)\n"
     ]
    }
   ],
   "source": [
    "Data=pd.read_csv('BreastCancer.csv').sample(frac=1).dropna()\n",
    "X_df=Data.iloc[0:-3,1:-1]\n",
    "Y_df=Data['Class'][0:-3]\n",
    "x=X_df.values\n",
    "y=Y_df.values\n",
    "print(x.shape, y.shape)\n",
    "k=10 #Number of folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9441176470588235\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[428,  25],\n",
       "       [ 13, 214]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "N=x.shape[0]\n",
    "ypredM1=[]\n",
    "test_scoreM1=[]\n",
    "for l in range(k):\n",
    "    ind = np.arange(l * int(N / k), (l + 1) * int(N / k))\n",
    "    x_train=np.delete(x,ind, axis=0)\n",
    "    y_train=np.delete(y,ind)\n",
    "    x_test=x[ind]\n",
    "    y_test=y[ind]\n",
    "    \n",
    "    model=DecisionTreeClassifier()\n",
    "    #cv_results=cross_validate(model,x_train, y_train, cv=5)\n",
    "    #cv_results['test_score'].mean()\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred=model.predict(x_test)\n",
    "    ypredM1.append(y_pred)\n",
    "    test_scoreM1.append(model.score(x_test, y_test))\n",
    "yM1=np.ndarray.flatten(np.array(ypredM1)).reshape(-1,1)\n",
    "\n",
    "print(np.array(test_scoreM1).mean())\n",
    "confusion_matrix(yM1,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support vector machine classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9573529411764706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\acer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\acer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\acer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\acer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\acer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\acer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\acer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\acer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\acer\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[414,   2],\n",
       "       [ 27, 237]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "N=x.shape[0]\n",
    "ypredM2=[]\n",
    "test_scoreM2=[]\n",
    "for l in range(k):\n",
    "    ind = np.arange(l * int(N / k), (l + 1) * int(N / k))\n",
    "    x_train=np.delete(x,ind, axis=0)\n",
    "    y_train=np.delete(y,ind)\n",
    "    x_test=x[ind]\n",
    "    y_test=y[ind]\n",
    "    \n",
    "    model=SVC()\n",
    "    #cv_results=cross_validate(model,x_train, y_train, cv=5)\n",
    "    #cv_results['test_score'].mean()\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred=model.predict(x_test)\n",
    "    ypredM2.append(y_pred)\n",
    "    test_scoreM2.append(model.score(x_test, y_test))\n",
    "yM2=np.ndarray.flatten(np.array(ypredM2)).reshape(-1,1)\n",
    "\n",
    "print(np.array(test_scoreM2).mean())\n",
    "confusion_matrix(yM2,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi layer perceptron classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\acer\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\acer\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\acer\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\acer\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\acer\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\acer\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\acer\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9691176470588235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[430,  10],\n",
       "       [ 11, 229]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "N=x.shape[0]\n",
    "ypredM3=[]\n",
    "\n",
    "test_scoreM3=[]\n",
    "for l in range(k):\n",
    "    ind = np.arange(l * int(N / k), (l + 1) * int(N / k))\n",
    "    x_train=np.delete(x,ind, axis=0)\n",
    "    y_train=np.delete(y,ind)\n",
    "    x_test=x[ind]\n",
    "    y_test=y[ind]\n",
    "    \n",
    "    model=MLPClassifier()\n",
    "    #cv_results=cross_validate(model,x_train, y_train, cv=5)\n",
    "    #cv_results['test_score'].mean()\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred=model.predict(x_test)\n",
    "    ypredM3.append(y_pred)\n",
    "    test_scoreM3.append(model.score(x_test, y_test))\n",
    "yM3=np.ndarray.flatten(np.array(ypredM3)).reshape(-1,1)\n",
    "\n",
    "print(np.array(test_scoreM3).mean())\n",
    "confusion_matrix(yM3,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking all the three predictions and using a decision tree classifier on them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(680, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_level_1=np.concatenate((np.concatenate((yM1, yM2), axis=1), yM3), axis=1)\n",
    "X_level_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9735294117647058\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[430,  10],\n",
       "       [ 11, 229]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N=X_level_1.shape[0]\n",
    "ypred_level_1=[]\n",
    "\n",
    "test_score_level_1=[]\n",
    "for l in range(k):\n",
    "    ind = np.arange(l * int(N / k), (l + 1) * int(N / k))\n",
    "    \n",
    "    x_train=np.delete(X_level_1,ind, axis=0)\n",
    "    y_train=np.delete(y,ind, axis=0)\n",
    "    \n",
    "    x_test=X_level_1[ind]\n",
    "    y_test=y[ind]\n",
    "    \n",
    "    model=DecisionTreeClassifier()\n",
    "    #cv_results=cross_validate(model,x_train, y_train, cv=5)\n",
    "    #cv_results['test_score'].mean()\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred=model.predict(x_test)\n",
    "    ypred_level_1.append(y_pred)\n",
    "    test_score_level_1.append(model.score(x_test, y_test))\n",
    "print(np.array(test_score_level_1).mean())\n",
    "confusion_matrix(yM3,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results: It doesn't seem that the ensemble stacking make the prediction better in this data set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
